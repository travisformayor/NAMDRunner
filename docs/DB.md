# Database & Data Schemas

This document defines all data persistence patterns for NAMDRunner, including SQLite schemas, JSON metadata formats, validation rules, and data management strategies.

## Table of Contents
- [JSON Metadata Schema](#json-metadata-schema)
  - [job_info.json (Single Job)](#job_infojson-single-job)
  - [Error Information Format](#error-information-format)
- [SQLite Schema (Phase 1 Version)](#sqlite-schema-phase-1-version)
  - [Jobs Table](#jobs-table)
  - [Application Metadata Table](#application-metadata-table)
  - [Python Implementation Reference](#python-implementation-reference)
- [File Organization Requirements](#file-organization-requirements)
  - [Directory Structure](#directory-structure)
  - [File Naming Conventions](#file-naming-conventions)
  - [Python Implementation Directory Pattern (Reference)](#python-implementation-directory-pattern-reference)
- [Validation Rules](#validation-rules)
  - [Job ID Format](#job-id-format)
  - [File Path Validation](#file-path-validation)
  - [Parameter Ranges](#parameter-ranges)
  - [Resource Limits (Alpine Cluster)](#resource-limits-alpine-cluster)
- [Schema Version Management](#schema-version-management)
  - [JSON Schema Version](#json-schema-version)
  - [Schema Development](#schema-development)
  - [Development Strategy](#development-strategy)
- [Data Type Mappings](#data-type-mappings)
  - [TypeScript to Rust](#typescript-to-rust)
  - [SQLite to Rust Type Mapping](#sqlite-to-rust-type-mapping)
- [Database Best Practices](#database-best-practices)
  - [Database Indexing Strategy](#database-indexing-strategy)
  - [Performance Guidelines](#performance-guidelines)
  - [Connection Management](#connection-management)
- [Data Integrity](#data-integrity)
  - [JSON Validation](#json-validation)
  - [Backup and Recovery](#backup-and-recovery)

## JSON Metadata Schema

### job_info.json (Single Job)
This file is created in each job directory on the cluster and contains all job metadata. The schema is generated by serializing the `JobInfo` struct from `src-tauri/src/types/core.rs`.

```json
{
  "job_id": "job_001",
  "job_name": "test_simulation",
  "status": "COMPLETED",
  "slurm_job_id": "12345678",
  "created_at": "2025-01-15T10:30:00Z",
  "updated_at": "2025-01-15T11:45:00Z",
  "submitted_at": "2025-01-15T10:35:00Z",
  "completed_at": "2025-01-15T11:00:00Z",
  "project_dir": "/projects/username/namdrunner_jobs/job_001",
  "scratch_dir": "/scratch/alpine/username/namdrunner_jobs/job_001",
  "error_info": null,
  "namd_config": {
    "steps": 50000,
    "temperature": 310.0,
    "timestep": 2.0,
    "outputname": "output",
    "dcd_freq": 1000,
    "restart_freq": 5000
  },
  "slurm_config": {
    "cores": 24,
    "memory": "16GB",
    "walltime": "02:00:00",
    "partition": "amilan",
    "qos": "normal"
  },
  "input_files": [
    {
      "name": "structure.pdb",
      "local_path": "input_files/structure.pdb",
      "remote_name": null,
      "file_type": "pdb"
    },
    {
      "name": "structure.psf",
      "local_path": "input_files/structure.psf",
      "remote_name": null,
      "file_type": "psf"
    },
    {
      "name": "parameters.prm",
      "local_path": "input_files/parameters.prm",
      "remote_name": null,
      "file_type": "prm"
    }
  ],
  "remote_directory": "/projects/username/namdrunner_jobs/job_001"
}
```

### Error Information Format
When jobs fail, the `error_info` field contains a simple error string:
```json
"error_info": "Job exceeded walltime limit"
```

## SQLite Schema (Phase 1 Version)

### Jobs Table
```sql
-- Jobs table for local cache
CREATE TABLE IF NOT EXISTS jobs (
    job_id TEXT PRIMARY KEY,               -- Our internal job ID
    job_name TEXT NOT NULL,
    status TEXT NOT NULL,                  -- JobStatus enum (CREATED, PENDING, RUNNING, COMPLETED, FAILED, CANCELLED)
    slurm_job_id TEXT,                     -- SLURM's job ID
    created_at TEXT NOT NULL,              -- RFC3339 timestamp
    updated_at TEXT,
    submitted_at TEXT,
    completed_at TEXT,
    project_dir TEXT,                      -- /projects/$USER/namdrunner_jobs/$JOB_ID
    scratch_dir TEXT,                      -- /scratch/alpine/$USER/namdrunner_jobs/$JOB_ID
    error_info TEXT                        -- Simple error string, null if no error
);

-- Indexes for performance
CREATE INDEX IF NOT EXISTS idx_jobs_status ON jobs(status);
CREATE INDEX IF NOT EXISTS idx_jobs_slurm_id ON jobs(slurm_job_id);
CREATE INDEX IF NOT EXISTS idx_jobs_updated ON jobs(updated_at);
```

**Note**: Job configuration data (NAMD config, SLURM config, input files) are **not stored in the database**. They are:
- Stored in-memory as part of the `JobInfo` struct during runtime
- Persisted to `job_info.json` on the cluster
- Loaded with defaults when reading from database (see `src-tauri/src/database/mod.rs::load_job`)

### Job Status History Table
Tracks all status changes for debugging and user feedback:

```sql
CREATE TABLE IF NOT EXISTS job_status_history (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    job_id TEXT NOT NULL,
    status TEXT NOT NULL,                  -- Status value at this point in time
    timestamp TEXT NOT NULL,               -- When the status changed (RFC3339)
    source TEXT NOT NULL,                  -- Where the update came from (e.g., "sync", "user_action", "automation")
    FOREIGN KEY (job_id) REFERENCES jobs (job_id)
);
```

**Usage**: Every status change is logged to this table via `database::add_status_history_entry()`. This provides:
- Complete audit trail of job lifecycle
- Debugging for status transition issues
- User-facing job history timeline

### Application Metadata Table
```sql
CREATE TABLE IF NOT EXISTS app_metadata (
    key TEXT PRIMARY KEY,
    value TEXT,
    updated_at TEXT
);

-- Insert schema version if not exists
INSERT OR IGNORE INTO app_metadata (key, value, updated_at)
VALUES ('schema_version', '1.0', datetime('now'));
```

### Python Implementation Reference

The Python version used more complex schemas that inform our design choices:

#### Job Groups (Future Implementation)
Python used UUID-based group IDs and multi-stage workflows:
```sql
-- Python implementation patterns (for reference)
-- job_groups table with UUID group IDs
-- job_stages table with stage_id, stage_number, stage_name
-- job_outputs table for cached SLURM stdout/stderr
```

#### Design Patterns
- **Data Integrity**: Validate JSON before parsing, handle missing fields gracefully
- **Status Values**: Use clear, descriptive status names
- **Timestamp Format**: ISO 8601 strings for consistency and parsing

## File Organization Requirements

### Directory Structure
> **See [`docs/reference/alpine-cluster-reference.md`](reference/alpine-cluster-reference.md)** for complete directory structure requirements and Alpine cluster file system details.

```
/projects/$USER/namdrunner_jobs/
└── {job_id}/
    ├── job_info.json           # This schema
    ├── input_files/
    │   ├── structure.pdb
    │   ├── structure.psf
    │   └── parameters.prm
    ├── config.namd             # Generated NAMD config
    ├── job.sbatch              # Generated SLURM script
    └── outputs/                # After job completion
        ├── {job_name}_{slurm_job_id}.out
        ├── {job_name}_{slurm_job_id}.err
        └── namd_output.log

/scratch/alpine/$USER/namdrunner_jobs/
└── {job_id}/                   # Working directory during execution
    ├── config.namd
    ├── job.sbatch
    ├── structure.pdb
    ├── structure.psf
    ├── parameters.prm
    ├── namd_output.log
    ├── output.dcd              # Trajectory
    ├── restart.coor            # Restart files
    ├── restart.vel
    └── restart.xsc
```

### File Naming Conventions
- **SLURM script**: `job.sbatch`
- **NAMD config**: `config.namd`
- **Job metadata**: `job_info.json`
- **SLURM Stdout**: `{job_name}_{slurm_job_id}.out`
- **SLURM Stderr**: `{job_name}_{slurm_job_id}.err`
- **NAMD Log**: `namd_output.log`
- **Trajectory**: `output.dcd`
- **Restart files**: `restart.coor`, `restart.vel`, `restart.xsc`

### Python Implementation Directory Pattern (Reference)
The Python version used this structure (informational for future multi-stage support):
```
/projects/$USER/namdrunner_jobs/
├── <job_group_name>/
│   ├── job_group_info.json      # Multi-stage metadata
│   ├── input_files/
│   └── stage_1/
       ├── config.namd
       ├── job.sbatch
       └── job_<id>.out
```

## Validation Rules

### Job ID Format
- **Pattern**: `^job_[0-9]{3,6}$`
- **Examples**: `job_001`, `job_12345`
- **Must be unique** within user's jobs

### File Path Validation
- **No absolute paths** in metadata
- **All paths relative** to job directory
- **No directory traversal** (`../`)
- **Allowed file extensions**: `.pdb`, `.psf`, `.prm`, `.namd`, `.sbatch`, `.out`, `.err`, `.log`, `.dcd`, `.coor`, `.vel`, `.xsc`

### Parameter Ranges
> **Note**: SLURM resource limits are defined in [`docs/reference/alpine-cluster-reference.md`](reference/alpine-cluster-reference.md) and may vary by partition.

```typescript
interface ValidationRules {
  namd: {
    steps: { min: 1, max: 100000000 };
    temperature: { min: 200, max: 400 };  // Kelvin
    timestep: { min: 0.1, max: 4.0 };     // femtoseconds
  };
  slurm: {
    cores: { min: 1, max: 128 };          // Max for amilan128c
    memory_gb: { min: 1, max: 256 };      // Varies by partition
    walltime_hours: { min: 0.1, max: 168 }; // Up to 7 days with long QoS
  };
}
```

### Resource Limits (Alpine Cluster)
> **For current resource limits, partition details, and QoS specifications, see [`docs/reference/alpine-cluster-reference.md`](reference/alpine-cluster-reference.md)**.

- **Default partition**: "amilan"
- **Default QOS**: "normal"

## Schema Version Management

### JSON Schema Version
- **Always include** `schema_version` field for tracking current implementation
- **Version 1.0**: Current single-job implementation
- **Future iterations**: May implement job groups, multi-stage workflows

### Schema Development
```sql
-- Current implementation pattern
-- Breaking changes are acceptable during development
-- No migration compatibility required
```

### Development Strategy
- **Graceful degradation** for unknown fields in JSON
- **Schema version** for tracking current implementation
- **Iterative development** - phases can break previous implementations
- **Breaking changes are acceptable** during development

## Data Type Mappings

### TypeScript to Rust
```rust
// String types
pub type JobId = String;          // job_001, job_002, etc.
pub type SlurmJobId = String;     // SLURM's numeric job ID as string
pub type Timestamp = DateTime<Utc>; // ISO 8601 in JSON, DateTime in Rust

// Status enums (must match exactly)
#[derive(Serialize, Deserialize)]
pub enum JobStatus {
    #[serde(rename = "CREATED")]
    Created,
    #[serde(rename = "PENDING")]
    Pending,
    #[serde(rename = "RUNNING")]
    Running,
    #[serde(rename = "COMPLETED")]
    Completed,
    #[serde(rename = "FAILED")]
    Failed,
    #[serde(rename = "CANCELLED")]
    Cancelled,
}
```

### SQLite to Rust Type Mapping
```rust
// SQLite TEXT -> Rust String
// SQLite INTEGER -> Rust i64
// SQLite REAL -> Rust f64
// JSON columns -> serde_json::Value -> structured types
```

## Database Best Practices

### Database Indexing Strategy
- **Primary lookups**: job_id (primary key)
- **Status queries**: idx_jobs_status for filtering by status
- **SLURM integration**: idx_jobs_slurm_id for mapping SLURM jobs to our jobs
- **Temporal queries**: idx_jobs_updated for recent activity

### Performance Guidelines
1. **Use transactions** for multi-row operations
2. **Batch inserts** for bulk operations
3. **Prepare statements** for repeated queries
4. **Index foreign keys** and commonly queried columns
5. **Validate JSON** before storage to prevent corruption
6. **JSON validation** prevents corrupt data from breaking the app
7. **SQLite WAL mode** recommended for concurrent access
8. **Regular maintenance** of completed job records may be needed
9. **Backup strategy** should include both SQLite and project directories
10. **Schema changes** can be breaking during development

### Connection Management
- **Connection pooling** for concurrent access
- **WAL mode** for better read/write concurrency
- **Foreign key constraints** enabled
- **Proper transaction boundaries** around related operations

## Data Integrity

### JSON Validation
All JSON stored in SQLite should be validated against schemas before insertion:
```rust
// Example validation pattern
fn validate_namd_config(json: &str) -> Result<NamdConfig, ValidationError> {
    let config: NamdConfig = serde_json::from_str(json)?;

    if config.steps < 1 || config.steps > 100_000_000 {
        return Err(ValidationError::InvalidSteps);
    }

    Ok(config)
}
```

### Backup and Recovery
- **Automatic backups** before schema migrations
- **Point-in-time recovery** using SQLite WAL files
- **Data export** capabilities for user data portability
- **Corruption detection** and recovery procedures

---

*For IPC interfaces and API contracts, see [`docs/API.md`](API.md).*
*For cluster-specific file system details, see [`docs/reference/alpine-cluster-reference.md`](reference/alpine-cluster-reference.md).*